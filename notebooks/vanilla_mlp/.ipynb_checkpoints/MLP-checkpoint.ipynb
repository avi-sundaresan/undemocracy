{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 821,
     "status": "ok",
     "timestamp": 1661222862232,
     "user": {
      "displayName": "Avi Sundaresan",
      "userId": "08297856679941143696"
     },
     "user_tz": 420
    },
    "id": "egqMGfopyf0I",
    "outputId": "6696527f-5a26-4409-8d9a-3488dc1503ca"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "import csv\n",
    "import pandas as pd\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 192,
     "status": "ok",
     "timestamp": 1660780106767,
     "user": {
      "displayName": "Avi Sundaresan",
      "userId": "08297856679941143696"
     },
     "user_tz": 420
    },
    "id": "Ha8lxxlQXST3"
   },
   "outputs": [],
   "source": [
    "new_data = pd.read_csv('undemocracy/data/new_data.csv')\n",
    "dataset = new_data[['Median Age', 'White', 'Black', 'AI/AN', 'PI', 'Other', 'Two Plus', 'Emp-LF Ratio', 'High School', 'Bachelor', 'Advanced', '% households w/ seniors', '% poverty', 'party_democrat', 'party_republican', 'inc_democrat', 'inc_republican', 'winner']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 517
    },
    "executionInfo": {
     "elapsed": 237,
     "status": "ok",
     "timestamp": 1660780107789,
     "user": {
      "displayName": "Avi Sundaresan",
      "userId": "08297856679941143696"
     },
     "user_tz": 420
    },
    "id": "80YFCA6-Zt4u",
    "outputId": "5b92bf18-51dd-4b40-e1c9-5093ab3f2b14"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Median Age</th>\n",
       "      <th>White</th>\n",
       "      <th>Black</th>\n",
       "      <th>AI/AN</th>\n",
       "      <th>PI</th>\n",
       "      <th>Other</th>\n",
       "      <th>Two Plus</th>\n",
       "      <th>Emp-LF Ratio</th>\n",
       "      <th>High School</th>\n",
       "      <th>Bachelor</th>\n",
       "      <th>Advanced</th>\n",
       "      <th>% households w/ seniors</th>\n",
       "      <th>% poverty</th>\n",
       "      <th>party_democrat</th>\n",
       "      <th>party_republican</th>\n",
       "      <th>inc_democrat</th>\n",
       "      <th>inc_republican</th>\n",
       "      <th>winner</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.428044</td>\n",
       "      <td>0.641809</td>\n",
       "      <td>0.416794</td>\n",
       "      <td>0.038793</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.013072</td>\n",
       "      <td>0.034615</td>\n",
       "      <td>0.407407</td>\n",
       "      <td>0.783529</td>\n",
       "      <td>0.247649</td>\n",
       "      <td>0.193443</td>\n",
       "      <td>0.437500</td>\n",
       "      <td>0.404130</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.428044</td>\n",
       "      <td>0.641809</td>\n",
       "      <td>0.416794</td>\n",
       "      <td>0.038793</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.013072</td>\n",
       "      <td>0.034615</td>\n",
       "      <td>0.407407</td>\n",
       "      <td>0.783529</td>\n",
       "      <td>0.247649</td>\n",
       "      <td>0.193443</td>\n",
       "      <td>0.437500</td>\n",
       "      <td>0.404130</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.372694</td>\n",
       "      <td>0.605134</td>\n",
       "      <td>0.468702</td>\n",
       "      <td>0.012931</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.019608</td>\n",
       "      <td>0.046154</td>\n",
       "      <td>0.419753</td>\n",
       "      <td>0.715294</td>\n",
       "      <td>0.217868</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.413194</td>\n",
       "      <td>0.427729</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.372694</td>\n",
       "      <td>0.605134</td>\n",
       "      <td>0.468702</td>\n",
       "      <td>0.012931</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.019608</td>\n",
       "      <td>0.046154</td>\n",
       "      <td>0.419753</td>\n",
       "      <td>0.715294</td>\n",
       "      <td>0.217868</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.413194</td>\n",
       "      <td>0.427729</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.357934</td>\n",
       "      <td>0.671149</td>\n",
       "      <td>0.381679</td>\n",
       "      <td>0.008621</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.017429</td>\n",
       "      <td>0.042308</td>\n",
       "      <td>0.404321</td>\n",
       "      <td>0.712941</td>\n",
       "      <td>0.208464</td>\n",
       "      <td>0.213115</td>\n",
       "      <td>0.378472</td>\n",
       "      <td>0.424779</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1204</th>\n",
       "      <td>0.446494</td>\n",
       "      <td>0.916870</td>\n",
       "      <td>0.013740</td>\n",
       "      <td>0.099138</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.041394</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.905882</td>\n",
       "      <td>0.274295</td>\n",
       "      <td>0.173770</td>\n",
       "      <td>0.350694</td>\n",
       "      <td>0.171091</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1205</th>\n",
       "      <td>0.335793</td>\n",
       "      <td>0.935208</td>\n",
       "      <td>0.009160</td>\n",
       "      <td>0.094828</td>\n",
       "      <td>0.008197</td>\n",
       "      <td>0.034858</td>\n",
       "      <td>0.069231</td>\n",
       "      <td>0.787037</td>\n",
       "      <td>0.920000</td>\n",
       "      <td>0.289969</td>\n",
       "      <td>0.229508</td>\n",
       "      <td>0.284722</td>\n",
       "      <td>0.200590</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1206</th>\n",
       "      <td>0.335793</td>\n",
       "      <td>0.935208</td>\n",
       "      <td>0.009160</td>\n",
       "      <td>0.094828</td>\n",
       "      <td>0.008197</td>\n",
       "      <td>0.034858</td>\n",
       "      <td>0.069231</td>\n",
       "      <td>0.787037</td>\n",
       "      <td>0.920000</td>\n",
       "      <td>0.289969</td>\n",
       "      <td>0.229508</td>\n",
       "      <td>0.284722</td>\n",
       "      <td>0.200590</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1207</th>\n",
       "      <td>0.335793</td>\n",
       "      <td>0.935208</td>\n",
       "      <td>0.009160</td>\n",
       "      <td>0.094828</td>\n",
       "      <td>0.008197</td>\n",
       "      <td>0.034858</td>\n",
       "      <td>0.069231</td>\n",
       "      <td>0.787037</td>\n",
       "      <td>0.920000</td>\n",
       "      <td>0.289969</td>\n",
       "      <td>0.229508</td>\n",
       "      <td>0.284722</td>\n",
       "      <td>0.200590</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1208</th>\n",
       "      <td>0.335793</td>\n",
       "      <td>0.935208</td>\n",
       "      <td>0.009160</td>\n",
       "      <td>0.094828</td>\n",
       "      <td>0.008197</td>\n",
       "      <td>0.034858</td>\n",
       "      <td>0.069231</td>\n",
       "      <td>0.787037</td>\n",
       "      <td>0.920000</td>\n",
       "      <td>0.289969</td>\n",
       "      <td>0.229508</td>\n",
       "      <td>0.284722</td>\n",
       "      <td>0.200590</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1209 rows × 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Median Age     White     Black     AI/AN        PI     Other  Two Plus  \\\n",
       "0       0.428044  0.641809  0.416794  0.038793  0.000000  0.013072  0.034615   \n",
       "1       0.428044  0.641809  0.416794  0.038793  0.000000  0.013072  0.034615   \n",
       "2       0.372694  0.605134  0.468702  0.012931  0.000000  0.019608  0.046154   \n",
       "3       0.372694  0.605134  0.468702  0.012931  0.000000  0.019608  0.046154   \n",
       "4       0.357934  0.671149  0.381679  0.008621  0.000000  0.017429  0.042308   \n",
       "...          ...       ...       ...       ...       ...       ...       ...   \n",
       "1204    0.446494  0.916870  0.013740  0.099138  0.000000  0.041394  0.050000   \n",
       "1205    0.335793  0.935208  0.009160  0.094828  0.008197  0.034858  0.069231   \n",
       "1206    0.335793  0.935208  0.009160  0.094828  0.008197  0.034858  0.069231   \n",
       "1207    0.335793  0.935208  0.009160  0.094828  0.008197  0.034858  0.069231   \n",
       "1208    0.335793  0.935208  0.009160  0.094828  0.008197  0.034858  0.069231   \n",
       "\n",
       "      Emp-LF Ratio  High School  Bachelor  Advanced  % households w/ seniors  \\\n",
       "0         0.407407     0.783529  0.247649  0.193443                 0.437500   \n",
       "1         0.407407     0.783529  0.247649  0.193443                 0.437500   \n",
       "2         0.419753     0.715294  0.217868  0.200000                 0.413194   \n",
       "3         0.419753     0.715294  0.217868  0.200000                 0.413194   \n",
       "4         0.404321     0.712941  0.208464  0.213115                 0.378472   \n",
       "...            ...          ...       ...       ...                      ...   \n",
       "1204      0.888889     0.905882  0.274295  0.173770                 0.350694   \n",
       "1205      0.787037     0.920000  0.289969  0.229508                 0.284722   \n",
       "1206      0.787037     0.920000  0.289969  0.229508                 0.284722   \n",
       "1207      0.787037     0.920000  0.289969  0.229508                 0.284722   \n",
       "1208      0.787037     0.920000  0.289969  0.229508                 0.284722   \n",
       "\n",
       "      % poverty  party_democrat  party_republican  inc_democrat  \\\n",
       "0      0.404130               0                 1             0   \n",
       "1      0.404130               1                 0             0   \n",
       "2      0.427729               0                 1             0   \n",
       "3      0.427729               1                 0             0   \n",
       "4      0.424779               1                 0             0   \n",
       "...         ...             ...               ...           ...   \n",
       "1204   0.171091               0                 1             0   \n",
       "1205   0.200590               0                 0             0   \n",
       "1206   0.200590               1                 0             0   \n",
       "1207   0.200590               0                 1             0   \n",
       "1208   0.200590               0                 0             0   \n",
       "\n",
       "      inc_republican  winner  \n",
       "0                  1       1  \n",
       "1                  1       0  \n",
       "2                  1       1  \n",
       "3                  1       0  \n",
       "4                  1       0  \n",
       "...              ...     ...  \n",
       "1204               1       1  \n",
       "1205               1       0  \n",
       "1206               1       0  \n",
       "1207               1       1  \n",
       "1208               1       0  \n",
       "\n",
       "[1209 rows x 18 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "executionInfo": {
     "elapsed": 345,
     "status": "ok",
     "timestamp": 1660780341663,
     "user": {
      "displayName": "Avi Sundaresan",
      "userId": "08297856679941143696"
     },
     "user_tz": 420
    },
    "id": "RedxzYS7aW2k"
   },
   "outputs": [],
   "source": [
    "X = dataset.iloc[:,0:16]\n",
    "Y = dataset.iloc[:,17]\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.3, random_state=0) #70:30 train-test-split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 428,
     "status": "ok",
     "timestamp": 1660780821631,
     "user": {
      "displayName": "Avi Sundaresan",
      "userId": "08297856679941143696"
     },
     "user_tz": 420
    },
    "id": "xW0857X-a39X"
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(12, input_shape=(16,), activation='tanh'))\n",
    "model.add(Dense(8, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "executionInfo": {
     "elapsed": 222,
     "status": "ok",
     "timestamp": 1660780822549,
     "user": {
      "displayName": "Avi Sundaresan",
      "userId": "08297856679941143696"
     },
     "user_tz": 420
    },
    "id": "VzoVbR3ea5AU"
   },
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8941,
     "status": "ok",
     "timestamp": 1660780832407,
     "user": {
      "displayName": "Avi Sundaresan",
      "userId": "08297856679941143696"
     },
     "user_tz": 420
    },
    "id": "Zd-m2o-Aa5G8",
    "outputId": "100a50a8-c321-47c0-cbc0-fce6e21775f7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 0.2184 - accuracy: 0.9216 - val_loss: 0.2821 - val_accuracy: 0.9118\n",
      "Epoch 2/150\n",
      "34/34 [==============================] - 0s 752us/step - loss: 0.2175 - accuracy: 0.9246 - val_loss: 0.2807 - val_accuracy: 0.9118\n",
      "Epoch 3/150\n",
      "34/34 [==============================] - 0s 751us/step - loss: 0.2177 - accuracy: 0.9201 - val_loss: 0.2787 - val_accuracy: 0.9059\n",
      "Epoch 4/150\n",
      "34/34 [==============================] - 0s 760us/step - loss: 0.2182 - accuracy: 0.9260 - val_loss: 0.2788 - val_accuracy: 0.9118\n",
      "Epoch 5/150\n",
      "34/34 [==============================] - 0s 728us/step - loss: 0.2180 - accuracy: 0.9246 - val_loss: 0.2831 - val_accuracy: 0.9059\n",
      "Epoch 6/150\n",
      "34/34 [==============================] - 0s 756us/step - loss: 0.2176 - accuracy: 0.9201 - val_loss: 0.2806 - val_accuracy: 0.9118\n",
      "Epoch 7/150\n",
      "34/34 [==============================] - 0s 752us/step - loss: 0.2165 - accuracy: 0.9216 - val_loss: 0.2820 - val_accuracy: 0.9118\n",
      "Epoch 8/150\n",
      "34/34 [==============================] - 0s 756us/step - loss: 0.2182 - accuracy: 0.9231 - val_loss: 0.2798 - val_accuracy: 0.9059\n",
      "Epoch 9/150\n",
      "34/34 [==============================] - 0s 750us/step - loss: 0.2163 - accuracy: 0.9231 - val_loss: 0.2821 - val_accuracy: 0.9118\n",
      "Epoch 10/150\n",
      "34/34 [==============================] - 0s 750us/step - loss: 0.2174 - accuracy: 0.9231 - val_loss: 0.2811 - val_accuracy: 0.9059\n",
      "Epoch 11/150\n",
      "34/34 [==============================] - 0s 780us/step - loss: 0.2180 - accuracy: 0.9216 - val_loss: 0.2817 - val_accuracy: 0.9118\n",
      "Epoch 12/150\n",
      "34/34 [==============================] - 0s 738us/step - loss: 0.2163 - accuracy: 0.9260 - val_loss: 0.2841 - val_accuracy: 0.9059\n",
      "Epoch 13/150\n",
      "34/34 [==============================] - 0s 780us/step - loss: 0.2172 - accuracy: 0.9201 - val_loss: 0.2808 - val_accuracy: 0.9059\n",
      "Epoch 14/150\n",
      "34/34 [==============================] - 0s 765us/step - loss: 0.2179 - accuracy: 0.9231 - val_loss: 0.2787 - val_accuracy: 0.9118\n",
      "Epoch 15/150\n",
      "34/34 [==============================] - 0s 755us/step - loss: 0.2156 - accuracy: 0.9246 - val_loss: 0.2822 - val_accuracy: 0.9059\n",
      "Epoch 16/150\n",
      "34/34 [==============================] - 0s 785us/step - loss: 0.2167 - accuracy: 0.9246 - val_loss: 0.2823 - val_accuracy: 0.9059\n",
      "Epoch 17/150\n",
      "34/34 [==============================] - 0s 756us/step - loss: 0.2173 - accuracy: 0.9231 - val_loss: 0.2821 - val_accuracy: 0.9059\n",
      "Epoch 18/150\n",
      "34/34 [==============================] - 0s 806us/step - loss: 0.2167 - accuracy: 0.9246 - val_loss: 0.2800 - val_accuracy: 0.9118\n",
      "Epoch 19/150\n",
      "34/34 [==============================] - 0s 771us/step - loss: 0.2163 - accuracy: 0.9231 - val_loss: 0.2831 - val_accuracy: 0.9059\n",
      "Epoch 20/150\n",
      "34/34 [==============================] - 0s 730us/step - loss: 0.2161 - accuracy: 0.9201 - val_loss: 0.2842 - val_accuracy: 0.9118\n",
      "Epoch 21/150\n",
      "34/34 [==============================] - 0s 778us/step - loss: 0.2170 - accuracy: 0.9201 - val_loss: 0.2811 - val_accuracy: 0.9059\n",
      "Epoch 22/150\n",
      "34/34 [==============================] - 0s 759us/step - loss: 0.2184 - accuracy: 0.9216 - val_loss: 0.2832 - val_accuracy: 0.9059\n",
      "Epoch 23/150\n",
      "34/34 [==============================] - 0s 735us/step - loss: 0.2152 - accuracy: 0.9231 - val_loss: 0.2823 - val_accuracy: 0.9118\n",
      "Epoch 24/150\n",
      "34/34 [==============================] - 0s 782us/step - loss: 0.2154 - accuracy: 0.9246 - val_loss: 0.2821 - val_accuracy: 0.9118\n",
      "Epoch 25/150\n",
      "34/34 [==============================] - 0s 768us/step - loss: 0.2152 - accuracy: 0.9246 - val_loss: 0.2836 - val_accuracy: 0.9118\n",
      "Epoch 26/150\n",
      "34/34 [==============================] - 0s 797us/step - loss: 0.2152 - accuracy: 0.9260 - val_loss: 0.2832 - val_accuracy: 0.9118\n",
      "Epoch 27/150\n",
      "34/34 [==============================] - 0s 788us/step - loss: 0.2164 - accuracy: 0.9216 - val_loss: 0.2831 - val_accuracy: 0.9059\n",
      "Epoch 28/150\n",
      "34/34 [==============================] - 0s 734us/step - loss: 0.2177 - accuracy: 0.9216 - val_loss: 0.2831 - val_accuracy: 0.9118\n",
      "Epoch 29/150\n",
      "34/34 [==============================] - 0s 779us/step - loss: 0.2150 - accuracy: 0.9246 - val_loss: 0.2795 - val_accuracy: 0.9059\n",
      "Epoch 30/150\n",
      "34/34 [==============================] - 0s 754us/step - loss: 0.2151 - accuracy: 0.9216 - val_loss: 0.2807 - val_accuracy: 0.9118\n",
      "Epoch 31/150\n",
      "34/34 [==============================] - 0s 820us/step - loss: 0.2158 - accuracy: 0.9231 - val_loss: 0.2825 - val_accuracy: 0.9118\n",
      "Epoch 32/150\n",
      "34/34 [==============================] - 0s 796us/step - loss: 0.2140 - accuracy: 0.9231 - val_loss: 0.2839 - val_accuracy: 0.9059\n",
      "Epoch 33/150\n",
      "34/34 [==============================] - 0s 767us/step - loss: 0.2175 - accuracy: 0.9216 - val_loss: 0.2856 - val_accuracy: 0.9059\n",
      "Epoch 34/150\n",
      "34/34 [==============================] - 0s 750us/step - loss: 0.2151 - accuracy: 0.9231 - val_loss: 0.2821 - val_accuracy: 0.9118\n",
      "Epoch 35/150\n",
      "34/34 [==============================] - 0s 753us/step - loss: 0.2148 - accuracy: 0.9260 - val_loss: 0.2808 - val_accuracy: 0.9059\n",
      "Epoch 36/150\n",
      "34/34 [==============================] - 0s 758us/step - loss: 0.2157 - accuracy: 0.9246 - val_loss: 0.2832 - val_accuracy: 0.9059\n",
      "Epoch 37/150\n",
      "34/34 [==============================] - 0s 761us/step - loss: 0.2163 - accuracy: 0.9201 - val_loss: 0.2826 - val_accuracy: 0.9118\n",
      "Epoch 38/150\n",
      "34/34 [==============================] - 0s 754us/step - loss: 0.2139 - accuracy: 0.9231 - val_loss: 0.2838 - val_accuracy: 0.9059\n",
      "Epoch 39/150\n",
      "34/34 [==============================] - 0s 777us/step - loss: 0.2155 - accuracy: 0.9246 - val_loss: 0.2822 - val_accuracy: 0.9059\n",
      "Epoch 40/150\n",
      "34/34 [==============================] - 0s 786us/step - loss: 0.2155 - accuracy: 0.9231 - val_loss: 0.2837 - val_accuracy: 0.9118\n",
      "Epoch 41/150\n",
      "34/34 [==============================] - 0s 753us/step - loss: 0.2142 - accuracy: 0.9246 - val_loss: 0.2814 - val_accuracy: 0.9118\n",
      "Epoch 42/150\n",
      "34/34 [==============================] - 0s 748us/step - loss: 0.2136 - accuracy: 0.9246 - val_loss: 0.2846 - val_accuracy: 0.9118\n",
      "Epoch 43/150\n",
      "34/34 [==============================] - 0s 749us/step - loss: 0.2155 - accuracy: 0.9231 - val_loss: 0.2855 - val_accuracy: 0.9118\n",
      "Epoch 44/150\n",
      "34/34 [==============================] - 0s 788us/step - loss: 0.2139 - accuracy: 0.9216 - val_loss: 0.2856 - val_accuracy: 0.9118\n",
      "Epoch 45/150\n",
      "34/34 [==============================] - 0s 804us/step - loss: 0.2151 - accuracy: 0.9216 - val_loss: 0.2814 - val_accuracy: 0.9118\n",
      "Epoch 46/150\n",
      "34/34 [==============================] - 0s 753us/step - loss: 0.2153 - accuracy: 0.9216 - val_loss: 0.2830 - val_accuracy: 0.9118\n",
      "Epoch 47/150\n",
      "34/34 [==============================] - 0s 767us/step - loss: 0.2136 - accuracy: 0.9216 - val_loss: 0.2847 - val_accuracy: 0.9118\n",
      "Epoch 48/150\n",
      "34/34 [==============================] - 0s 845us/step - loss: 0.2136 - accuracy: 0.9246 - val_loss: 0.2845 - val_accuracy: 0.9059\n",
      "Epoch 49/150\n",
      "34/34 [==============================] - 0s 823us/step - loss: 0.2147 - accuracy: 0.9246 - val_loss: 0.2797 - val_accuracy: 0.9118\n",
      "Epoch 50/150\n",
      "34/34 [==============================] - 0s 820us/step - loss: 0.2129 - accuracy: 0.9216 - val_loss: 0.2857 - val_accuracy: 0.9118\n",
      "Epoch 51/150\n",
      "34/34 [==============================] - 0s 787us/step - loss: 0.2135 - accuracy: 0.9231 - val_loss: 0.2843 - val_accuracy: 0.9059\n",
      "Epoch 52/150\n",
      "34/34 [==============================] - 0s 815us/step - loss: 0.2142 - accuracy: 0.9246 - val_loss: 0.2862 - val_accuracy: 0.9118\n",
      "Epoch 53/150\n",
      "34/34 [==============================] - 0s 801us/step - loss: 0.2144 - accuracy: 0.9216 - val_loss: 0.2849 - val_accuracy: 0.9059\n",
      "Epoch 54/150\n",
      "34/34 [==============================] - 0s 770us/step - loss: 0.2144 - accuracy: 0.9260 - val_loss: 0.2838 - val_accuracy: 0.9118\n",
      "Epoch 55/150\n",
      "34/34 [==============================] - 0s 831us/step - loss: 0.2137 - accuracy: 0.9216 - val_loss: 0.2855 - val_accuracy: 0.9118\n",
      "Epoch 56/150\n",
      "34/34 [==============================] - 0s 792us/step - loss: 0.2132 - accuracy: 0.9260 - val_loss: 0.2850 - val_accuracy: 0.9118\n",
      "Epoch 57/150\n",
      "34/34 [==============================] - 0s 817us/step - loss: 0.2132 - accuracy: 0.9231 - val_loss: 0.2861 - val_accuracy: 0.9118\n",
      "Epoch 58/150\n",
      "34/34 [==============================] - 0s 813us/step - loss: 0.2145 - accuracy: 0.9216 - val_loss: 0.2876 - val_accuracy: 0.9059\n",
      "Epoch 59/150\n",
      "34/34 [==============================] - 0s 827us/step - loss: 0.2137 - accuracy: 0.9201 - val_loss: 0.2861 - val_accuracy: 0.9059\n",
      "Epoch 60/150\n",
      "34/34 [==============================] - 0s 803us/step - loss: 0.2125 - accuracy: 0.9260 - val_loss: 0.2823 - val_accuracy: 0.9118\n",
      "Epoch 61/150\n",
      "34/34 [==============================] - 0s 771us/step - loss: 0.2140 - accuracy: 0.9231 - val_loss: 0.2839 - val_accuracy: 0.9059\n",
      "Epoch 62/150\n",
      "34/34 [==============================] - 0s 832us/step - loss: 0.2128 - accuracy: 0.9246 - val_loss: 0.2856 - val_accuracy: 0.9118\n",
      "Epoch 63/150\n",
      "34/34 [==============================] - 0s 767us/step - loss: 0.2126 - accuracy: 0.9231 - val_loss: 0.2852 - val_accuracy: 0.9118\n",
      "Epoch 64/150\n",
      "34/34 [==============================] - 0s 761us/step - loss: 0.2125 - accuracy: 0.9260 - val_loss: 0.2840 - val_accuracy: 0.9118\n",
      "Epoch 65/150\n",
      "34/34 [==============================] - 0s 771us/step - loss: 0.2127 - accuracy: 0.9231 - val_loss: 0.2852 - val_accuracy: 0.9118\n",
      "Epoch 66/150\n",
      "34/34 [==============================] - 0s 820us/step - loss: 0.2128 - accuracy: 0.9246 - val_loss: 0.2845 - val_accuracy: 0.9118\n",
      "Epoch 67/150\n",
      "34/34 [==============================] - 0s 754us/step - loss: 0.2120 - accuracy: 0.9246 - val_loss: 0.2853 - val_accuracy: 0.9118\n",
      "Epoch 68/150\n",
      "34/34 [==============================] - 0s 804us/step - loss: 0.2123 - accuracy: 0.9260 - val_loss: 0.2840 - val_accuracy: 0.9118\n",
      "Epoch 69/150\n",
      "34/34 [==============================] - 0s 803us/step - loss: 0.2142 - accuracy: 0.9246 - val_loss: 0.2885 - val_accuracy: 0.9059\n",
      "Epoch 70/150\n",
      "34/34 [==============================] - 0s 779us/step - loss: 0.2118 - accuracy: 0.9216 - val_loss: 0.2843 - val_accuracy: 0.9118\n",
      "Epoch 71/150\n",
      "34/34 [==============================] - 0s 805us/step - loss: 0.2123 - accuracy: 0.9246 - val_loss: 0.2859 - val_accuracy: 0.9118\n",
      "Epoch 72/150\n",
      "34/34 [==============================] - 0s 831us/step - loss: 0.2144 - accuracy: 0.9201 - val_loss: 0.2875 - val_accuracy: 0.9059\n",
      "Epoch 73/150\n",
      "34/34 [==============================] - 0s 778us/step - loss: 0.2111 - accuracy: 0.9231 - val_loss: 0.2834 - val_accuracy: 0.9118\n",
      "Epoch 74/150\n",
      "34/34 [==============================] - 0s 785us/step - loss: 0.2120 - accuracy: 0.9231 - val_loss: 0.2846 - val_accuracy: 0.9118\n",
      "Epoch 75/150\n",
      "34/34 [==============================] - 0s 808us/step - loss: 0.2111 - accuracy: 0.9275 - val_loss: 0.2867 - val_accuracy: 0.9118\n",
      "Epoch 76/150\n",
      "34/34 [==============================] - 0s 782us/step - loss: 0.2113 - accuracy: 0.9246 - val_loss: 0.2873 - val_accuracy: 0.9059\n",
      "Epoch 77/150\n",
      "34/34 [==============================] - 0s 818us/step - loss: 0.2138 - accuracy: 0.9201 - val_loss: 0.2858 - val_accuracy: 0.9118\n",
      "Epoch 78/150\n",
      "34/34 [==============================] - 0s 783us/step - loss: 0.2142 - accuracy: 0.9246 - val_loss: 0.2875 - val_accuracy: 0.9118\n",
      "Epoch 79/150\n",
      "34/34 [==============================] - 0s 779us/step - loss: 0.2128 - accuracy: 0.9231 - val_loss: 0.2870 - val_accuracy: 0.9118\n",
      "Epoch 80/150\n",
      "34/34 [==============================] - 0s 802us/step - loss: 0.2114 - accuracy: 0.9231 - val_loss: 0.2870 - val_accuracy: 0.9059\n",
      "Epoch 81/150\n",
      "34/34 [==============================] - 0s 768us/step - loss: 0.2119 - accuracy: 0.9231 - val_loss: 0.2874 - val_accuracy: 0.9118\n",
      "Epoch 82/150\n",
      "34/34 [==============================] - 0s 744us/step - loss: 0.2137 - accuracy: 0.9260 - val_loss: 0.2852 - val_accuracy: 0.9118\n",
      "Epoch 83/150\n",
      "34/34 [==============================] - 0s 760us/step - loss: 0.2113 - accuracy: 0.9246 - val_loss: 0.2877 - val_accuracy: 0.9118\n",
      "Epoch 84/150\n",
      "34/34 [==============================] - 0s 745us/step - loss: 0.2111 - accuracy: 0.9246 - val_loss: 0.2842 - val_accuracy: 0.9118\n",
      "Epoch 85/150\n",
      "34/34 [==============================] - 0s 758us/step - loss: 0.2110 - accuracy: 0.9231 - val_loss: 0.2841 - val_accuracy: 0.9118\n",
      "Epoch 86/150\n",
      "34/34 [==============================] - 0s 790us/step - loss: 0.2119 - accuracy: 0.9216 - val_loss: 0.2877 - val_accuracy: 0.9059\n",
      "Epoch 87/150\n",
      "34/34 [==============================] - 0s 775us/step - loss: 0.2120 - accuracy: 0.9216 - val_loss: 0.2866 - val_accuracy: 0.9118\n",
      "Epoch 88/150\n",
      "34/34 [==============================] - 0s 795us/step - loss: 0.2105 - accuracy: 0.9246 - val_loss: 0.2859 - val_accuracy: 0.9118\n",
      "Epoch 89/150\n",
      "34/34 [==============================] - 0s 772us/step - loss: 0.2113 - accuracy: 0.9275 - val_loss: 0.2847 - val_accuracy: 0.9118\n",
      "Epoch 90/150\n",
      "34/34 [==============================] - 0s 752us/step - loss: 0.2111 - accuracy: 0.9231 - val_loss: 0.2870 - val_accuracy: 0.9059\n",
      "Epoch 91/150\n",
      "34/34 [==============================] - 0s 734us/step - loss: 0.2110 - accuracy: 0.9246 - val_loss: 0.2885 - val_accuracy: 0.9118\n",
      "Epoch 92/150\n",
      "34/34 [==============================] - 0s 758us/step - loss: 0.2124 - accuracy: 0.9216 - val_loss: 0.2853 - val_accuracy: 0.9118\n",
      "Epoch 93/150\n",
      "34/34 [==============================] - 0s 741us/step - loss: 0.2111 - accuracy: 0.9260 - val_loss: 0.2863 - val_accuracy: 0.9118\n",
      "Epoch 94/150\n",
      "34/34 [==============================] - 0s 762us/step - loss: 0.2105 - accuracy: 0.9260 - val_loss: 0.2863 - val_accuracy: 0.9118\n",
      "Epoch 95/150\n",
      "34/34 [==============================] - 0s 750us/step - loss: 0.2103 - accuracy: 0.9231 - val_loss: 0.2865 - val_accuracy: 0.9118\n",
      "Epoch 96/150\n",
      "34/34 [==============================] - 0s 727us/step - loss: 0.2117 - accuracy: 0.9216 - val_loss: 0.2873 - val_accuracy: 0.9059\n",
      "Epoch 97/150\n",
      "34/34 [==============================] - 0s 734us/step - loss: 0.2119 - accuracy: 0.9260 - val_loss: 0.2859 - val_accuracy: 0.9118\n",
      "Epoch 98/150\n",
      "34/34 [==============================] - 0s 744us/step - loss: 0.2103 - accuracy: 0.9260 - val_loss: 0.2865 - val_accuracy: 0.9118\n",
      "Epoch 99/150\n",
      "34/34 [==============================] - 0s 764us/step - loss: 0.2104 - accuracy: 0.9231 - val_loss: 0.2873 - val_accuracy: 0.9118\n",
      "Epoch 100/150\n",
      "34/34 [==============================] - 0s 763us/step - loss: 0.2105 - accuracy: 0.9246 - val_loss: 0.2857 - val_accuracy: 0.9118\n",
      "Epoch 101/150\n",
      "34/34 [==============================] - 0s 753us/step - loss: 0.2104 - accuracy: 0.9246 - val_loss: 0.2865 - val_accuracy: 0.9118\n",
      "Epoch 102/150\n",
      "34/34 [==============================] - 0s 774us/step - loss: 0.2104 - accuracy: 0.9260 - val_loss: 0.2849 - val_accuracy: 0.9118\n",
      "Epoch 103/150\n",
      "34/34 [==============================] - 0s 765us/step - loss: 0.2107 - accuracy: 0.9246 - val_loss: 0.2849 - val_accuracy: 0.9118\n",
      "Epoch 104/150\n",
      "34/34 [==============================] - 0s 742us/step - loss: 0.2101 - accuracy: 0.9260 - val_loss: 0.2867 - val_accuracy: 0.9118\n",
      "Epoch 105/150\n",
      "34/34 [==============================] - 0s 771us/step - loss: 0.2113 - accuracy: 0.9201 - val_loss: 0.2867 - val_accuracy: 0.9118\n",
      "Epoch 106/150\n",
      "34/34 [==============================] - 0s 784us/step - loss: 0.2099 - accuracy: 0.9231 - val_loss: 0.2820 - val_accuracy: 0.9118\n",
      "Epoch 107/150\n",
      "34/34 [==============================] - 0s 793us/step - loss: 0.2092 - accuracy: 0.9290 - val_loss: 0.2877 - val_accuracy: 0.9118\n",
      "Epoch 108/150\n",
      "34/34 [==============================] - 0s 757us/step - loss: 0.2106 - accuracy: 0.9216 - val_loss: 0.2862 - val_accuracy: 0.9059\n",
      "Epoch 109/150\n",
      "34/34 [==============================] - 0s 765us/step - loss: 0.2097 - accuracy: 0.9260 - val_loss: 0.2840 - val_accuracy: 0.9118\n",
      "Epoch 110/150\n",
      "34/34 [==============================] - 0s 774us/step - loss: 0.2093 - accuracy: 0.9260 - val_loss: 0.2861 - val_accuracy: 0.9118\n",
      "Epoch 111/150\n",
      "34/34 [==============================] - 0s 745us/step - loss: 0.2097 - accuracy: 0.9246 - val_loss: 0.2850 - val_accuracy: 0.9118\n",
      "Epoch 112/150\n",
      "34/34 [==============================] - 0s 787us/step - loss: 0.2088 - accuracy: 0.9246 - val_loss: 0.2875 - val_accuracy: 0.9118\n",
      "Epoch 113/150\n",
      "34/34 [==============================] - 0s 740us/step - loss: 0.2109 - accuracy: 0.9260 - val_loss: 0.2880 - val_accuracy: 0.9059\n",
      "Epoch 114/150\n",
      "34/34 [==============================] - 0s 782us/step - loss: 0.2097 - accuracy: 0.9246 - val_loss: 0.2854 - val_accuracy: 0.9118\n",
      "Epoch 115/150\n",
      "34/34 [==============================] - 0s 767us/step - loss: 0.2101 - accuracy: 0.9260 - val_loss: 0.2884 - val_accuracy: 0.9059\n",
      "Epoch 116/150\n",
      "34/34 [==============================] - 0s 827us/step - loss: 0.2108 - accuracy: 0.9246 - val_loss: 0.2855 - val_accuracy: 0.9118\n",
      "Epoch 117/150\n",
      "34/34 [==============================] - 0s 750us/step - loss: 0.2090 - accuracy: 0.9246 - val_loss: 0.2871 - val_accuracy: 0.9118\n",
      "Epoch 118/150\n",
      "34/34 [==============================] - 0s 793us/step - loss: 0.2097 - accuracy: 0.9216 - val_loss: 0.2855 - val_accuracy: 0.9118\n",
      "Epoch 119/150\n",
      "34/34 [==============================] - 0s 744us/step - loss: 0.2106 - accuracy: 0.9275 - val_loss: 0.2851 - val_accuracy: 0.9118\n",
      "Epoch 120/150\n",
      "34/34 [==============================] - 0s 799us/step - loss: 0.2101 - accuracy: 0.9216 - val_loss: 0.2859 - val_accuracy: 0.9118\n",
      "Epoch 121/150\n",
      "34/34 [==============================] - 0s 782us/step - loss: 0.2086 - accuracy: 0.9231 - val_loss: 0.2879 - val_accuracy: 0.9059\n",
      "Epoch 122/150\n",
      "34/34 [==============================] - 0s 699us/step - loss: 0.2097 - accuracy: 0.9231 - val_loss: 0.2842 - val_accuracy: 0.9118\n",
      "Epoch 123/150\n",
      "34/34 [==============================] - 0s 792us/step - loss: 0.2095 - accuracy: 0.9260 - val_loss: 0.2861 - val_accuracy: 0.9118\n",
      "Epoch 124/150\n",
      "34/34 [==============================] - 0s 707us/step - loss: 0.2096 - accuracy: 0.9246 - val_loss: 0.2864 - val_accuracy: 0.9118\n",
      "Epoch 125/150\n",
      "34/34 [==============================] - 0s 774us/step - loss: 0.2088 - accuracy: 0.9260 - val_loss: 0.2869 - val_accuracy: 0.9118\n",
      "Epoch 126/150\n",
      "34/34 [==============================] - 0s 739us/step - loss: 0.2088 - accuracy: 0.9246 - val_loss: 0.2849 - val_accuracy: 0.9118\n",
      "Epoch 127/150\n",
      "34/34 [==============================] - 0s 766us/step - loss: 0.2083 - accuracy: 0.9260 - val_loss: 0.2862 - val_accuracy: 0.9118\n",
      "Epoch 128/150\n",
      "34/34 [==============================] - 0s 774us/step - loss: 0.2091 - accuracy: 0.9231 - val_loss: 0.2843 - val_accuracy: 0.9118\n",
      "Epoch 129/150\n",
      "34/34 [==============================] - 0s 740us/step - loss: 0.2077 - accuracy: 0.9275 - val_loss: 0.2892 - val_accuracy: 0.9118\n",
      "Epoch 130/150\n",
      "34/34 [==============================] - 0s 779us/step - loss: 0.2085 - accuracy: 0.9231 - val_loss: 0.2871 - val_accuracy: 0.9118\n",
      "Epoch 131/150\n",
      "34/34 [==============================] - 0s 764us/step - loss: 0.2105 - accuracy: 0.9260 - val_loss: 0.2847 - val_accuracy: 0.9118\n",
      "Epoch 132/150\n",
      "34/34 [==============================] - 0s 765us/step - loss: 0.2085 - accuracy: 0.9246 - val_loss: 0.2858 - val_accuracy: 0.9118\n",
      "Epoch 133/150\n",
      "34/34 [==============================] - 0s 775us/step - loss: 0.2091 - accuracy: 0.9246 - val_loss: 0.2865 - val_accuracy: 0.9118\n",
      "Epoch 134/150\n",
      "34/34 [==============================] - 0s 724us/step - loss: 0.2098 - accuracy: 0.9231 - val_loss: 0.2898 - val_accuracy: 0.9118\n",
      "Epoch 135/150\n",
      "34/34 [==============================] - 0s 794us/step - loss: 0.2100 - accuracy: 0.9275 - val_loss: 0.2834 - val_accuracy: 0.9118\n",
      "Epoch 136/150\n",
      "34/34 [==============================] - 0s 741us/step - loss: 0.2085 - accuracy: 0.9260 - val_loss: 0.2857 - val_accuracy: 0.9118\n",
      "Epoch 137/150\n",
      "34/34 [==============================] - 0s 774us/step - loss: 0.2082 - accuracy: 0.9260 - val_loss: 0.2843 - val_accuracy: 0.9118\n",
      "Epoch 138/150\n",
      "34/34 [==============================] - 0s 711us/step - loss: 0.2080 - accuracy: 0.9216 - val_loss: 0.2868 - val_accuracy: 0.9118\n",
      "Epoch 139/150\n",
      "34/34 [==============================] - 0s 774us/step - loss: 0.2088 - accuracy: 0.9246 - val_loss: 0.2821 - val_accuracy: 0.9176\n",
      "Epoch 140/150\n",
      "34/34 [==============================] - 0s 722us/step - loss: 0.2074 - accuracy: 0.9231 - val_loss: 0.2833 - val_accuracy: 0.9118\n",
      "Epoch 141/150\n",
      "34/34 [==============================] - 0s 786us/step - loss: 0.2076 - accuracy: 0.9275 - val_loss: 0.2854 - val_accuracy: 0.9118\n",
      "Epoch 142/150\n",
      "34/34 [==============================] - 0s 769us/step - loss: 0.2081 - accuracy: 0.9246 - val_loss: 0.2890 - val_accuracy: 0.9059\n",
      "Epoch 143/150\n",
      "34/34 [==============================] - 0s 786us/step - loss: 0.2087 - accuracy: 0.9290 - val_loss: 0.2845 - val_accuracy: 0.9118\n",
      "Epoch 144/150\n",
      "34/34 [==============================] - 0s 731us/step - loss: 0.2078 - accuracy: 0.9260 - val_loss: 0.2841 - val_accuracy: 0.9118\n",
      "Epoch 145/150\n",
      "34/34 [==============================] - 0s 771us/step - loss: 0.2076 - accuracy: 0.9246 - val_loss: 0.2862 - val_accuracy: 0.9118\n",
      "Epoch 146/150\n",
      "34/34 [==============================] - 0s 713us/step - loss: 0.2086 - accuracy: 0.9246 - val_loss: 0.2870 - val_accuracy: 0.9118\n",
      "Epoch 147/150\n",
      "34/34 [==============================] - 0s 764us/step - loss: 0.2074 - accuracy: 0.9231 - val_loss: 0.2855 - val_accuracy: 0.9118\n",
      "Epoch 148/150\n",
      "34/34 [==============================] - 0s 701us/step - loss: 0.2090 - accuracy: 0.9275 - val_loss: 0.2871 - val_accuracy: 0.9118\n",
      "Epoch 149/150\n",
      "34/34 [==============================] - 0s 750us/step - loss: 0.2095 - accuracy: 0.9216 - val_loss: 0.2839 - val_accuracy: 0.9118\n",
      "Epoch 150/150\n",
      "34/34 [==============================] - 0s 702us/step - loss: 0.2079 - accuracy: 0.9246 - val_loss: 0.2846 - val_accuracy: 0.9118\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2a2c95d00>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=25)\n",
    "model.fit(X_train, Y_train, epochs=150, batch_size=20, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 157,
     "status": "ok",
     "timestamp": 1660780835510,
     "user": {
      "displayName": "Avi Sundaresan",
      "userId": "08297856679941143696"
     },
     "user_tz": 420
    },
    "id": "YeIw8Ijea5Jt",
    "outputId": "db299978-e015-41e1-ae0d-7b837a086560"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - 0s 490us/step - loss: 0.2057 - accuracy: 0.9229\n"
     ]
    }
   ],
   "source": [
    "_, accuracy = model.evaluate(X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - 0s 482us/step\n"
     ]
    }
   ],
   "source": [
    "pred_probs = model.predict(X_test)\n",
    "threshold = 0.5\n",
    "y_pred = [1 if elem > threshold else 0 for elem in pred_probs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1660765838097,
     "user": {
      "displayName": "Avi Sundaresan",
      "userId": "08297856679941143696"
     },
     "user_tz": 420
    },
    "id": "oHa8iyxv7Wj-",
    "outputId": "875fd52d-9cf0-4789-dcdd-b6b4cf991f5c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[217,  14],\n",
       "       [ 14, 118]])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnf_matrix = metrics.confusion_matrix(Y_test, y_pred)\n",
    "cnf_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9228650137741047\n",
      "Precision: 0.8939393939393939\n",
      "Recall: 0.8939393939393939\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy:\",metrics.accuracy_score(Y_test, y_pred))\n",
    "print(\"Precision:\",metrics.precision_score(Y_test, y_pred))\n",
    "print(\"Recall:\",metrics.recall_score(Y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 295
    },
    "executionInfo": {
     "elapsed": 547,
     "status": "ok",
     "timestamp": 1660765809709,
     "user": {
      "displayName": "Avi Sundaresan",
      "userId": "08297856679941143696"
     },
     "user_tz": 420
    },
    "id": "dUgl41z-7vHO",
    "outputId": "585b9a71-42f1-48b3-dc60-c4e07dc21969"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fpr_rf, tpr_rf, _ = metrics.roc_curve(Y_test, pred_probs)\n",
    "\n",
    "plt.figure(1)\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "auc = metrics.roc_auc_score(Y_test, pred_probs)\n",
    "plt.plot(fpr_rf, tpr_rf, label='RF, AUC=' + str(auc))\n",
    "plt.xlabel('False positive rate')\n",
    "plt.ylabel('True positive rate')\n",
    "plt.title('ROC Curve')\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics.auc(fpr_rf, tpr_rf)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Candidate Classification ANN.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
